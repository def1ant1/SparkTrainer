# DGX AI Trainer - Quick Start Guide

## ğŸš€ Getting Started in 5 Minutes

### Step 1: Extract the Application
```bash
tar -xzf dgx-ai-trainer.tar.gz
cd dgx-ai-trainer
```

### Step 2: Run Setup
```bash
chmod +x setup.sh
./setup.sh
```

This will:
- Create Python virtual environment
- Install all dependencies (PyTorch, TensorFlow, Transformers)
- Install React frontend dependencies
- Create startup scripts

### Step 3: Start the Application
```bash
./start.sh
```

Or start components separately:
```bash
# Terminal 1 - Backend
./start_backend.sh

# Terminal 2 - Frontend
./start_frontend.sh
```

### Step 4: Open in Browser
Navigate to: **http://localhost:3000**

---

## ğŸ“Š What You Can Do

### 1. Train Models from Scratch
- Custom neural networks
- ResNet architectures
- Transformer models
- Fully configurable layers and hyperparameters

### 2. Fine-tune Pre-trained Models
- **PyTorch**: ResNet18/50, VGG16, DenseNet121
- **Hugging Face**: BERT, GPT-2, T5, LLaMA
- Transfer learning with layer freezing
- Adaptive learning rates

### 3. Monitor Training
- Real-time job status
- Training logs and metrics
- GPU utilization tracking
- Job queue management

---

## ğŸ¯ Quick Training Examples

### Example 1: Train a Simple Classifier
```json
{
  "name": "My First Model",
  "type": "train",
  "framework": "pytorch",
  "config": {
    "epochs": 10,
    "batch_size": 32,
    "learning_rate": 0.001,
    "num_classes": 10
  }
}
```

### Example 2: Fine-tune BERT
```json
{
  "name": "BERT Fine-tune",
  "type": "finetune",
  "framework": "huggingface",
  "config": {
    "model_name": "bert-base-uncased",
    "epochs": 3,
    "batch_size": 16,
    "learning_rate": 2e-5,
    "num_classes": 2
  }
}
```

---

## ğŸ—‚ï¸ Project Structure

```
dgx-ai-trainer/
â”œâ”€â”€ backend/              # Flask API
â”‚   â”œâ”€â”€ app.py           # Main server
â”‚   â””â”€â”€ requirements.txt # Python deps
â”œâ”€â”€ frontend/            # React UI
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ App.jsx     # Main component
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ training_scripts/    # Training code
â”‚   â”œâ”€â”€ train_pytorch.py
â”‚   â”œâ”€â”€ finetune_pytorch.py
â”‚   â””â”€â”€ train_huggingface.py
â”œâ”€â”€ jobs/                # Job metadata
â”œâ”€â”€ models/              # Saved models
â”œâ”€â”€ logs/                # Training logs
â””â”€â”€ setup.sh            # Setup script
```

---

## ğŸ’¡ Key Features

âœ… **Multi-Framework Support**: PyTorch, TensorFlow, Hugging Face
âœ… **Real-time Monitoring**: Track jobs and GPU usage
âœ… **Job Queue System**: Automatic scheduling
âœ… **Model Management**: Save and organize trained models
âœ… **Web Interface**: Easy-to-use React dashboard
âœ… **RESTful API**: Programmatic access
âœ… **DGX Optimized**: Built for NVIDIA DGX Spark

---

## ğŸ”§ Configuration Options

### Training Parameters
- **epochs**: Number of training iterations
- **batch_size**: Samples per gradient update
- **learning_rate**: Optimization step size
- **optimizer**: adam, sgd, adamw
- **architecture**: Model structure

### Fine-tuning Options
- **model_name**: Base model to fine-tune
- **freeze_layers**: Freeze pre-trained layers
- **use_scheduler**: Learning rate scheduling
- **weight_decay**: L2 regularization

---

## ğŸ“ˆ Monitoring Your Jobs

### Dashboard View
- Total GPUs available
- Running jobs count
- Queued jobs
- Saved models
- GPU memory usage

### Job Details
- Status: queued â†’ running â†’ completed
- Configuration
- Real-time logs
- Training metrics
- Cancel option

---

## ğŸ³ Docker Deployment (Optional)

For containerized deployment:

```bash
# Build and start containers
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

Access at: **http://localhost**

---

## ğŸ› ï¸ Customization

### Add Your Own Data
Edit training scripts in `training_scripts/`:
```python
# Replace dummy data with your dataset
dataset = YourCustomDataset('/path/to/data')
train_loader = DataLoader(dataset, batch_size=batch_size)
```

### Add Custom Architectures
Extend model classes in training scripts:
```python
class MyCustomModel(nn.Module):
    def __init__(self, config):
        super().__init__()
        # Your architecture here
```

### Add New Frameworks
Create new training script:
```bash
cp training_scripts/train_pytorch.py training_scripts/train_myframework.py
# Modify for your framework
```

---

## ğŸ” Troubleshooting

### Port Already in Use
```bash
# Kill process on port 5000
sudo lsof -t -i:5000 | xargs kill -9

# Kill process on port 3000
sudo lsof -t -i:3000 | xargs kill -9
```

### CUDA Out of Memory
- Reduce batch_size
- Enable mixed precision
- Use gradient accumulation

### Module Not Found
```bash
cd backend
source venv/bin/activate
pip install -r requirements.txt
```

### Frontend Won't Start
```bash
cd frontend
rm -rf node_modules
npm install
```

---

## ğŸ“š Additional Resources

- **README.md**: Comprehensive documentation
- **EXAMPLES.md**: Training configuration examples
- **API Docs**: Backend API reference
- **logs/**: Check training logs for errors

---

## ğŸ“ Best Practices

1. **Start Small**: Test with small models first
2. **Monitor GPUs**: Use `nvidia-smi` to check utilization
3. **Save Checkpoints**: Models auto-save after training
4. **Use Validation**: Split your data properly
5. **Track Experiments**: Name jobs clearly

---

## ğŸ“ Support

For issues:
1. Check `logs/` directory for error messages
2. Verify GPU availability: `nvidia-smi`
3. Check backend logs: `tail -f logs/[job-id].log`
4. Review training script output

---

## ğŸš€ Next Steps

1. âœ… Complete setup
2. âœ… Start the application
3. âœ… Create your first training job
4. âœ… Monitor training progress
5. âœ… Use your trained model

**Happy Training! ğŸ‰**
